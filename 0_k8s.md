Esto esta bueno porque escala muy bien, terraform es lento no escala (a nivel de gestión con mas recursos equipos etc...)

Terraform va a seguir por tiempo, salvo que salga algo nuevo.

En un futuro con mucho avance Terraform se podría quedar para hacer el primer cluster o cosas mas complejas al ser codigo (se podría hacer con minikube o similar pero no...)

No tiene el plan de terraform, habria que mirar los logs y los eventos de kube.

Tiene la comunidad de K8s detras (aunque la de Terraform es muy grande), y esta creciendo muy rapido.

OS dejo el enlace a la comparativa del final

<https://youtu.be/dWbEvHOtljg?t=731>

## Notas

### Zero-downtime rolling deployments in k8s

Detected that when some deployments are restarted while receiving requests, it results in some failed requests.

After some investigation, it has been discovered that with the current k8s version, a race condition can happen in the process of deleting a pod that is referenced by a service, resulting in requests to an already deleted pod. In order to mitigate this and reach zero-downtime deployments it is recommended to introduce in the affected containers a preStop hook that waits for some time before starting the shutdown process.

[Graceful shutdown](https://learnk8s.io/graceful-shutdown)
[K8s pod graceful shutdown](https://foxutech.medium.com/kubernetes-pod-graceful-shutdown-how-a9a46e0b1e53)
[Graceful k8s deployments](https://engineering.rakuten.today/post/graceful-k8s-delpoyments/)
[Delaying shutdown to wait for pod deletion](https://blog.gruntwork.io/delaying-shutdown-to-wait-for-pod-deletion-propagation-445f779a8304)

## Resource Governance

https://kubernetes.io/docs/concepts/policy/resource-quotas/
https://kubernetes.io/docs/concepts/policy/limit-range/
https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler
https://www.fairwinds.com/blog/introducing-goldilocks-a-tool-for-recommending-resource-requests

https://home.robusta.dev/blog/stop-using-cpu-limits
https://www.perfectscale.io/blog/kubernetes-cpu-limits

https://dnastacio.medium.com/why-you-should-keep-using-cpu-limits-on-kubernetes-60c4e50dfc61

```
this article tho is based off the pretense that internally developed services are included in perfrormance engineering exercises to ensure that internally developed services work well under throttling circumstances 
clearly we are not there :D
the trade off here is saying essentially, to dedicate time to optimize your app to run well under a CPU limited ecosystem vs allowing for uncapped with control mechanisms in place to allow for maximum performance
if this was the case, I would 100% agree
on the no-limits scenario, we must implement monitors on actual cpu consumption of production wokloads, as to make those the actual requests and hence preventing starvation (of idle capacity) when more load is added to the cluster (HPA, new deploymentc, etc).
```